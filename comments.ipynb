{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Analysis on Youtube Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Ming Zhao <br>\n",
    ">Jan 18, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains comments for videos related to animals and/or pets. The comments are comma separated, with a header line defining the field names: \n",
    "    1. creator_name: name of the YouTube channel creator. \n",
    "    2. userid: integer identifier for the users commenting on the YouTube channels.\n",
    "    3. comment: text of the comments made by the users.  \n",
    "\n",
    "**Step 1**: Exploring and Preprocessing Data\n",
    "* Loading and Exploring Data. \n",
    "* Labeling data: Identify Cat/Dog Owners.\n",
    "* Tokenizing Text: Split text into smaller units.\n",
    "* Removing Stopwords: Exclude words without significant meaning.\n",
    "* Splitting Data: Divde dataset into training and testing.\n",
    "\n",
    "**Step 2**: Building and Evaluating Classifiers\n",
    "* Build classifiers for the cat/dog owners. <br>\n",
    "    -- Logistic Regression <br>\n",
    "    -- Random Forest <br>\n",
    "    -- Gradient-Boosted Trees <br>\n",
    "* Measure the performance of the classifiers.\n",
    "\n",
    "**Step 3**: Classifying All Users\n",
    "* Apply the cat/dog classifiers to all the users in the dataset. \n",
    "* Estimate the fraction of all users who are cat/dog owners.\n",
    "\n",
    "**Step 4**: Extracting Insights about Cat/Dog Owners\n",
    "* Find topics important to cat/dog owners.\n",
    "\n",
    "**Step 5**: Identifying Creators with Cat/Dog Owners in the Audience \n",
    "* Find creators with most comments by cat/dog owners. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/09/02 04:40:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .appName(\"Python Spark SQL\") \\\n",
    "        .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col\n",
    "from pyspark.sql.functions import regexp_replace\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import RegexTokenizer \n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.clustering import LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Exploration and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loadiing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_raw=spark.read.csv(\"animals_comments.csv\",inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------+--------------------+\n",
      "| creator_name|userid|             comment|\n",
      "+-------------+------+--------------------+\n",
      "| Doug The Pug|  87.0|I shared this to ...|\n",
      "| Doug The Pug|  87.0|  Super cute  😀🐕🐶|\n",
      "|  bulletproof| 530.0|stop saying get e...|\n",
      "|Meu Zoológico| 670.0|Tenho uma jiboia ...|\n",
      "|       ojatro|1031.0|I wanna see what ...|\n",
      "+-------------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5786944"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('creator_name', 'string'), ('userid', 'double'), ('comment', 'string')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1051\n"
     ]
    }
   ],
   "source": [
    "# count missing values\n",
    "for column in df_raw.columns:\n",
    "    print(df_raw.filter(df_raw[column].isNull()).count())\n",
    "\n",
    "# drop missing values    \n",
    "for column in df_raw.columns:\n",
    "    df_raw=df_raw.filter(df_raw[column].isNotNull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw=df_raw.withColumn(\"label\", \\\n",
    "        (when(col(\"comment\").like(\"%my dog%\"),1).when(col(\"comment\").like(\"%my dogs%\"),1) \\\n",
    "        .when(col(\"comment\").like(\"%my puppy%\"),1).when(col(\"comment\").like(\"%my puppies%\"),1) \\\n",
    "        .when(col(\"comment\").like(\"%my pup%\"),1).when(col(\"comment\").like(\"%mu pups%\"),1) \\\n",
    "        .when(col(\"comment\").like(\"%i have a dog%\"),1).when(col(\"comment\").like(\"%i have dogs%\"),1) \\\n",
    "        .when(col(\"comment\").like(\"%i have a puppy%\"),1).when(col(\"comment\").like(\"%i have puppies%\"),1) \\\n",
    "        .when(col(\"comment\").like(\"%i have a pup%\"),1).when(col(\"comment\").like(\"%i have pups%\"),1) \\\n",
    "        .when(col(\"comment\").like(\"%my cat%\"),1).when(col(\"comment\").like(\"%my cats%\"),1) \\\n",
    "        .when(col(\"comment\").like(\"%my kitty%\"),1).when(col(\"comment\").like(\"%my kitties%\"),1) \\\n",
    "        .when(col(\"comment\").like(\"%my kitten%\"),1).when(col(\"comment\").like(\"%my kittens%\"),1) \\\n",
    "        .when(col(\"comment\").like(\"%i have a cat%\"),1).when(col(\"comment\").like(\"%i have cats%\"),1) \\\n",
    "        .when(col(\"comment\").like(\"%i have a kitty%\"),1).when(col(\"comment\").like(\"%i have kitties%\"),1) \\\n",
    "        .when(col(\"comment\").like(\"%i have a kitten%\"),1).when(col(\"comment\").like(\"%i have kittens%\"),1) \\\n",
    "        .when(col(\"comment\").like(\"%my baby dog%\"),1).when(col(\"comment\").like(\"%my baby dogs%\"),1) \\\n",
    "        .when(col(\"comment\").like(\"%my baby cat%\"),1).when(col(\"comment\").like(\"%my baby cats%\"),1) \\\n",
    "        .when(col(\"comment\").like(\"%my little dog%\"),1).when(col(\"comment\").like(\"%my little cat%\"),1) \\\n",
    "        .otherwise(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:==================================>                      (6 + 4) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|label|  count|\n",
      "+-----+-------+\n",
      "|    1|  40215|\n",
      "|    0|5746729|\n",
      "+-----+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_raw.groupBy(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------------------------------------------------------------------+\n",
      "|comment                                                                                                  |\n",
      "+---------------------------------------------------------------------------------------------------------+\n",
      "|Now I want to try that with my dog!!!                                                                    |\n",
      "|I blow smoke in my cats ear right to his brain                                                           |\n",
      "|my dog lucky wont eat of his bowl hell only eat out peoples hands how do i get him to eat out of his bowl|\n",
      "|thats what my dog do                                                                                     |\n",
      "|Im so happy i think Im almost crying Im hugging my dog Ik its not a cat but its a animal that need love  |\n",
      "+---------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw.select(\"comment\").filter(df_raw[\"label\"]==1).show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all dog/cat owners\n",
    "label1_data = df_raw.filter(df_raw[\"label\"]==1) \n",
    "#label1_data= df_raw.filter(col(\"label\")==1) \n",
    "    \n",
    "# Select part of non-dog/cat-owners\n",
    "label0_data, label0_rest = df_raw.filter(df_raw[\"label\"]==0).randomSplit([0.05,0.95],seed=1991)\n",
    "\n",
    "# Combine selected observations\n",
    "all_data = label1_data.union(label0_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For faster speed\n",
    "data, rest = all_data.randomSplit([0.1,0.9],seed=1991)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:==============================>                         (11 + 9) / 20]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Count: 32764\n",
      "Proportion of Dog/Cat Owners in Dataset: 12.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 30:=====================================================>  (19 + 1) / 20]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "data_count = data.count()\n",
    "owner_count = data.filter(data[\"label\"]==1).count()\n",
    "print(\"Dataset Count: \" + str(data_count))\n",
    "print(\"Proportion of Dog/Cat Owners in Dataset: \" + str(round(owner_count/data_count*100,2)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline\n",
    "* Tokenizing Texts\n",
    "* Removing Stop-Words\n",
    "* Computing distributed Representation of Words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove numbers\n",
    "data = data.withColumn('comment', regexp_replace(data.comment, '[0-9]', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize, removing stopwords, take sequences of words representing documents\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"comment\", outputCol=\"words\", pattern=\"\\\\W\") # pattern=\"\\\\W\" removes punctuations and emojis                                                     \n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"words_clean\")\n",
    "word2Vec = Word2Vec(inputCol=\"words_clean\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a pipeline\n",
    "pipeline = Pipeline(stages=[regexTokenizer, remover, word2Vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/09/02 04:48:56 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "22/09/02 04:48:56 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Fit the pipeline on data\n",
    "pipeline_fit = pipeline.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data to a new one\n",
    "df = pipeline_fit.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+\n",
      "|label|               words|         words_clean|            features|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "|    1|[actually, i, use...|[actually, use, b...|[0.01119084873353...|\n",
      "|    1|[creo, que, el, s...|[creo, que, el, s...|[-0.3080230177276...|\n",
      "|    1|[wish, my, cat, d...|         [wish, cat]|[0.00823379866778...|\n",
      "|    1|[when, my, cat, n...|[cat, needs, food...|[0.02935355461456...|\n",
      "|    1|[taj, at, looks, ...|[taj, looks, like...|[0.00210698095615...|\n",
      "+-----+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"label\", \"words\", \"words_clean\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "train, test = df.randomSplit([0.8,0.2],seed=1991)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 26194\n",
      "Proportion of Dog/Cat Owners in Training Dataset: 12.24%\n"
     ]
    }
   ],
   "source": [
    "train_count = train.count()\n",
    "owner_count = train.filter(train[\"label\"]==1).count()\n",
    "print(\"Training Dataset Count: \" + str(train_count))\n",
    "print(\"Proportion of Dog/Cat Owners in Training Dataset: \" + str(round(owner_count/train_count*100,2)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Training and Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a logistic regression model\n",
    "lr = LogisticRegression(featuresCol=\"features\", labelCol=\"label\")\n",
    "\n",
    "# Tune model using ParamGridBuilder\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.maxIter, [10, 20, 30])\n",
    "             .addGrid(lr.regParam, [0.01, 0.1, 0.5, 1])\n",
    "             .addGrid(lr.elasticNetParam,[0, 0.5, 1]) \n",
    "             .build())\n",
    "\n",
    "# Define evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\",\n",
    "                                              labelCol=\"label\",\n",
    "                                              predictionCol=\"prediction\")\n",
    "\n",
    "\n",
    "# Build cross validation\n",
    "cv = CrossValidator(estimator=lr, \n",
    "                    estimatorParamMaps=paramGrid, \n",
    "                    evaluator=evaluator,\n",
    "                    numFolds=5, seed=1991)\n",
    "\n",
    "# Fit LR model to training data\n",
    "cv_model = cv.fit(train)\n",
    "\n",
    "# Extract best model\n",
    "best_LR_model = cv_model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularization Parameter: 0.01\n",
      "Maxmum Iterations: 30\n",
      "Regularization Method: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Extract model hyperparameters\n",
    "print(\"Regularization Parameter: {}\".format(best_LR_model.getRegParam()))\n",
    "print(\"Maxmum Iterations: {}\".format(best_LR_model.getMaxIter()))\n",
    "print(\"Regularization Method: {}\".format(best_LR_model.getElasticNetParam())) \n",
    "#1 for Lasso(L1); 0 for Ridge(L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Training Data: 0.88\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions on training data\n",
    "LR_prediction_train = best_LR_model.transform(train)\n",
    "LR_accuracy_train = evaluator.evaluate(LR_prediction_train)\n",
    "print(\"Accuracy for Training Data: {}\".format(round(LR_accuracy_train,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a gradient-boosted tree model\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", seed=1991)\n",
    "\n",
    "# Tune model using ParamGridBuilder\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(rf.numTrees, [20, 50, 100])\n",
    "             .addGrid(rf.maxDepth, [2, 5, 10])\n",
    "             .build())\n",
    "\n",
    "# Define evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\",\n",
    "                                              labelCol=\"label\",\n",
    "                                              predictionCol=\"prediction\")\n",
    "\n",
    "# Build cross validation\n",
    "cv = CrossValidator(estimator=rf, \n",
    "                    estimatorParamMaps=paramGrid, \n",
    "                    evaluator=evaluator,\n",
    "                    numFolds=5, seed=1991)\n",
    "\n",
    "# Fit GBT model to training data\n",
    "cv_model = cv.fit(train)\n",
    "\n",
    "# Extract best model\n",
    "best_RF_model = cv_model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Trees: 20\n",
      "Maximum Depth of The Tree: 10\n"
     ]
    }
   ],
   "source": [
    "# Extract model hyperparameters\n",
    "print(\"Number of Trees: {}\".format(best_RF_model.getNumTrees))\n",
    "print(\"Maximum Depth of The Tree: {}\".format(best_RF_model.getMaxDepth())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Training Data: 0.93\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions on training data\n",
    "RF_prediction_train = best_RF_model.transform(train)\n",
    "RF_accuracy_train = evaluator.evaluate(RF_prediction_train)\n",
    "print(\"Accuracy for Training Data: {}\".format(round(RF_accuracy_train,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient-Boosted Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest** and **GBT** are ensemble learning algorithms, which combine multiple decision trees to produce more powerful models. <br>\n",
    "\n",
    "Ensemble learning algorithms build upon other machine learning methods by combining models. The combination can be more powerful and accurate than any of the individual models. <br>\n",
    "\n",
    "The two algorithms use **Decision Trees** as the base models. The main difference is the order in which each component tree is trained. <br>\n",
    "\n",
    "**Random Forest** trains each tree independently using a random sample of the data. Since each tree in the random forest is trained independently, multiple trees can be trained in parallel. Such method refers to bootstrap aggregating, or **bagging** (independent models). <br>\n",
    "\n",
    "**GBT** trains one tree at a time, where each new tree helps to correct errors made by previously trained trees. Since GBT must train one tree at a time, training is only parallelized at the single tree level. Such method refers to **boosting** (sequential models). <br>\n",
    "\n",
    "In the end, both methods produce a weighted collection of **Decision Trees**. The ensemble model makes predictions by combining results from the individual trees. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/1400/1*-qr7ugMY0tvQOE1aoD3lVg.png\" width=\"500\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://miro.medium.com/max/1400/1*-qr7ugMY0tvQOE1aoD3lVg.png\"\n",
    ",width=500, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/4800/1*9MlWByZxGnVDVKvJpl3IXg.png\" width=\"500\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://miro.medium.com/max/4800/1*9MlWByZxGnVDVKvJpl3IXg.png\"\n",
    ",width=500, height=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a gradient-boosted tree model\n",
    "gbt = GBTClassifier(featuresCol=\"features\", labelCol=\"label\", seed=1991)\n",
    "\n",
    "# Tune model using ParamGridBuilder\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(gbt.maxIter, [10, 20, 30])\n",
    "             .addGrid(gbt.maxDepth, [5, 10, 20])\n",
    "             .build())\n",
    "\n",
    "# Define evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\",\n",
    "                                              labelCol=\"label\",\n",
    "                                              predictionCol=\"prediction\")\n",
    "\n",
    "# Build cross validation\n",
    "cv = CrossValidator(estimator=gbt, \n",
    "                    estimatorParamMaps=paramGrid, \n",
    "                    evaluator=evaluator,\n",
    "                    numFolds=5, seed=1991)\n",
    "\n",
    "# Fit GBT model to training data\n",
    "cv_model = cv.fit(train)\n",
    "\n",
    "# Extract best model\n",
    "best_GBT_model = cv_model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maxmum Iterations: 30\n",
      "Maximum Depth of The Tree: 5\n"
     ]
    }
   ],
   "source": [
    "# Extract model hyperparameters\n",
    "print(\"Maxmum Iterations: {}\".format(best_GBT_model.getMaxIter()))\n",
    "print(\"Maximum Depth of The Tree: {}\".format(best_GBT_model.getMaxDepth())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Training Data: 0.92\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions on training data\n",
    "GBT_prediction_train = best_GBT_model.transform(train)\n",
    "GBT_accuracy_train = evaluator.evaluate(GBT_prediction_train)\n",
    "print(\"Accuracy for Training Data: {}\".format(round(GBT_accuracy_train,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance on Testing Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy**, **precision**, and **recall** for RF and GBT are all higher than those for LR. RF and BST have similar accuracy, but RF has higher **precision** and GBT has higher **recall**. As we would like to correctly identify dog/cat owners, **recall** is more significant in this situation, and we conclude that **GBT** is more appropriate for predicting the result based on this data than the other two models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "LR_prediction_test = best_LR_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+----------+\n",
      "|label|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+----------+\n",
      "|    1|[1.56259321466050...|[0.82672514754066...|       0.0|\n",
      "|    1|[-0.0447241139494...|[0.48882083487423...|       1.0|\n",
      "|    1|[1.65312199092632...|[0.83931255011807...|       0.0|\n",
      "|    1|[-0.7763730808973...|[0.31510209608705...|       1.0|\n",
      "|    1|[0.87093261564528...|[0.70493971885251...|       0.0|\n",
      "+-----+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR_prediction_test.select(\"label\", \"rawPrediction\", \"probability\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "RF_prediction_test = best_RF_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+----------+\n",
      "|label|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+----------+\n",
      "|    1|[18.9322736322717...|[0.94661368161358...|       0.0|\n",
      "|    1|[6.87592279255087...|[0.34379613962754...|       1.0|\n",
      "|    1|[15.8015584919507...|[0.79007792459753...|       0.0|\n",
      "|    1|[6.18069803726720...|[0.30903490186336...|       1.0|\n",
      "|    1|[11.4144996489556...|[0.57072498244778...|       0.0|\n",
      "+-----+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RF_prediction_test.select(\"label\", \"rawPrediction\", \"probability\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "GBT_prediction_test = best_GBT_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+----------+\n",
      "|label|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+----------+\n",
      "|    1|[1.30976003468303...|[0.93210734115254...|       0.0|\n",
      "|    1|[-0.2455651688344...|[0.37962732516163...|       1.0|\n",
      "|    1|[1.07388398205819...|[0.89546001728828...|       0.0|\n",
      "|    1|[-0.5926512762559...|[0.23410012298118...|       1.0|\n",
      "|    1|[0.28808282795089...|[0.64018464740453...|       0.0|\n",
      "+-----+--------------------+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GBT_prediction_test.select(\"label\", \"rawPrediction\", \"probability\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(predictions):\n",
    "    \n",
    "  TP = predictions[(predictions[\"label\"] == 1) & (predictions[\"prediction\"] == 1.0)].count()\n",
    "  FP = predictions[(predictions[\"label\"] == 0) & (predictions[\"prediction\"] == 1.0)].count()\n",
    "  TN = predictions[(predictions[\"label\"] == 0) & (predictions[\"prediction\"] == 0.0)].count()\n",
    "  FN = predictions[(predictions[\"label\"] == 1) & (predictions[\"prediction\"] == 0.0)].count()\n",
    "\n",
    "  accuracy = (TP + TN) / (TP + FP + TN + FN)\n",
    "  precision = TP / (TP + FP)\n",
    "  recall = TP / (TP + FN)\n",
    "\n",
    "  print (\"True Positives:\", TP)\n",
    "  print (\"False Positives:\", FP)\n",
    "  print (\"True Negatives:\", TN)\n",
    "  print (\"False Negatives:\", FN)\n",
    "  print (\"Accuracy:\", accuracy)\n",
    "  print (\"Precision:\", precision)\n",
    "  print (\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result Evaluation Metrics for LR Model on Testing Data:\n",
      "True Positives: 153\n",
      "False Positives: 94\n",
      "True Negatives: 5533\n",
      "False Negatives: 636\n",
      "Accuracy: 0.8862219451371571\n",
      "Precision: 0.6194331983805668\n",
      "Recall: 0.19391634980988592\n"
     ]
    }
   ],
   "source": [
    "print(\"Result Evaluation Metrics for LR Model on Testing Data:\")\n",
    "model_evaluation(LR_prediction_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result Evaluation Metrics for RF Model on Testing Data:\n",
      "True Positives: 266\n",
      "False Positives: 106\n",
      "True Negatives: 5521\n",
      "False Negatives: 523\n",
      "Accuracy: 0.9019638403990025\n",
      "Precision: 0.7150537634408602\n",
      "Recall: 0.33713561470215464\n"
     ]
    }
   ],
   "source": [
    "print(\"Result Evaluation Metrics for RF Model on Testing Data:\")\n",
    "model_evaluation(RF_prediction_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result Evaluation Metrics for GBT Model on Testing Data:\n",
      "True Positives: 361\n",
      "False Positives: 178\n",
      "True Negatives: 5449\n",
      "False Negatives: 428\n",
      "Accuracy: 0.9055486284289277\n",
      "Precision: 0.6697588126159555\n",
      "Recall: 0.45754119138149557\n"
     ]
    }
   ],
   "source": [
    "print(\"Result Evaluation Metrics for GBT Model on Testing Data:\")\n",
    "model_evaluation(GBT_prediction_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Estimated Classification of Dog/Cat Owners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\text{Estimated fraction of dog/cat owners}=\\frac{\\#\\text{ of labeled owners }+ \\space \\#\\text{ of predicted owners without label}}{\\#\\text{ of total users}}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on whole data\n",
    "predictions = best_GBT_model.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled = df.filter(df[\"label\"]==1).count()\n",
    "predicted = predictions.filter((col(\"label\")==0)&(col(\"prediction\")==1.0)).count()\n",
    "fraction = (labeled+predicted)/data_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The labeled fraction of the cat/dog owners is 0.123\n"
     ]
    }
   ],
   "source": [
    "print(\"The labeled fraction of the cat/dog owners is \" + str(round(labeled/data_count,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated fraction of the cat/dog owners is 0.145\n"
     ]
    }
   ],
   "source": [
    "print(\"The estimated fraction of the cat/dog owners is \" + str(round(fraction,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analysis on Topics of Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identification of Important Topics to Dog/Cat Owners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select labeled and predicted owners \n",
    "df_owner = predictions.filter((col(\"label\")==1)|(col(\"prediction\")==1.0)).select(\"userid\",\"words_clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming words: break words down to their roots\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "stemmer_udf = udf(lambda tokens: [stemmer.stem(t) for t in tokens], ArrayType(StringType()))\n",
    "df_stemmed = df_owner.withColumn(\"words_stemmed\", stemmer_udf(\"words_clean\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_owner = df_stemmed.select('userid', 'words_stemmed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a countvectorizer model\n",
    "cv = CountVectorizer(inputCol=\"words_stemmed\", outputCol=\"features\", \n",
    "                     minTF=1, # minimum number of a word must appear in a document\n",
    "                     minDF=5) # minimum number of documents that a word must appear in\n",
    "cv_model = cv.fit(df_owner)\n",
    "count_vectors = cv_model.transform(df_owner).select(\"userid\", \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains a LDA model\n",
    "num_topics = 10\n",
    "top_n_words=10\n",
    "\n",
    "lda = LDA(k=num_topics, maxIter=20)\n",
    "LDA_model = lda.fit(count_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/spark/python/pyspark/sql/context.py:127: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "# Obtain indices of top n words\n",
    "topics = LDA_model.describeTopics(maxTermsPerTopic=top_n_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1667"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain a list of words\n",
    "vocabArray = cv_model.vocabulary\n",
    "len(vocabArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match words with index \n",
    "index_to_words = udf(lambda word_index: list([vocabArray[i] for i in word_index]))\n",
    "key_words = topics.select(index_to_words(topics.termIndices).alias('words'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------+\n",
      "|words                                                               |\n",
      "+--------------------------------------------------------------------+\n",
      "|[gotcha, cat, love, game, name, everyth, special, seem, bunni, talk]|\n",
      "|[daisi, bunni, grate, cream, cone, ice, like, hour, dog, took]      |\n",
      "|[kitten, enter, zone, meow, cat, dog, butt, fur, know, theyr]       |\n",
      "|[dog, like, game, hate, high, fuck, th, danc, feel, put]            |\n",
      "|[dog, cat, like, love, get, one, look, im, got, know]               |\n",
      "|[dog, like, outsid, clean, look, vet, get, puppi, hous, toy]        |\n",
      "|[dog, cat, gibson, marm, swim, like, snack, fed, want, support]     |\n",
      "|[dog, light, bed, hernia, give, control, grow, sale, want, dont]    |\n",
      "|[cat, minut, time, dog, one, year, com, belli, tree, get]           |\n",
      "|[dog, pls, love, vaccin, puppi, hurt, need, want, sooo, one]        |\n",
      "+--------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show topic*word matrix\n",
    "key_words.show(num_topics, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Popular Creators for Dog/Cat Owners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Who has the largest number of comments made by cat/dog owners?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions.createOrReplaceTempView(\"predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|        creator_name|number|\n",
      "+--------------------+------+\n",
      "|            The Dodo|   477|\n",
      "|    Cole & Marmalade|   312|\n",
      "|     Gohan The Husky|   248|\n",
      "|        Robin Seplut|   239|\n",
      "|Hope For Paws - O...|   235|\n",
      "|Zak Georges Dog T...|   231|\n",
      "|           Vet Ranch|   209|\n",
      "|  Taylor Nicole Dean|   192|\n",
      "|Gone to the Snow ...|   184|\n",
      "|          stacyvlogs|   170|\n",
      "|    Brave Wilderness|   166|\n",
      "|       Brian Barczyk|   161|\n",
      "|   Talking Kitty Cat|   133|\n",
      "|           meow meow|    91|\n",
      "|     Viktor Larkhill|    81|\n",
      "|        Paws Channel|    74|\n",
      "|          Funny Pets|    55|\n",
      "|    SlideShow ForFun|    55|\n",
      "|       Cat Man Chris|    49|\n",
      "|  The Pet Collective|    47|\n",
      "+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "creators = spark.sql(\"SELECT creator_name, count(creator_name) AS number \\\n",
    "                      FROM (SELECT creator_name FROM predictions WHERE label=1 OR prediction=1.0) \\\n",
    "                      GROUP BY creator_name \\\n",
    "                      ORDER BY number DESC\")\n",
    "creators.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
